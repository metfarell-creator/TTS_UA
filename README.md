# TTS UA Toolkit

Цей репозиторій містить дві суміжні реалізації для українського синтезу мовлення та дубляжу відео:

- **StyleTTS 2 Ukrainian EXP** — початковий експериментальний застосунок для інтерактивного синтезу мовлення зі стилями.
- **SoniTranslate UA** — портативний конвеєр для автоматичного дубляжу відео, що поєднує WhisperX та StyleTTS2 з веб-інтерфейсом Gradio.

---

## StyleTTS 2 Ukrainian EXP

### Ключові можливості
- **Gradio UI** з окремими вкладками для **Multi speaker** і **Single speaker**.
- Автоматична або ручна вербалізація тексту (додавання наголосів, заміна чисел тощо).
- Вибір голосу для багатоголосого режиму, контроль швидкості мовлення.
- Підтримка символу `+` для ручного виставлення наголосу.

### Швидкий старт
1. Переконайтеся, що в середовищі встановлено залежності з `requirements.txt`, включно з `huggingface_hub`.
2. Запустіть `run.bat` (Windows) або `python app.py` — під час першого старту застосунок автоматично завантажить моделі з Hugging Face:
   - `patriotyk/styletts2_ukrainian_multispeaker_hifigan`,
   - `patriotyk/styletts2_ukrainian_single`,
   - `skypro1111/mbart-large-50-verbalization`.
   Файли кешуються у папці `models/`, повторні запуски відпрацьовують офлайн.
3. Розмістіть локальні стилі голосів (`*.pt`) у папці `voices/` та файл стилю для single-режиму (`filatov.pt`) у корені проєкту.
4. Відкрийте адресу, вказану Gradio, у браузері та синтезуйте мовлення.

### Системні вимоги
- **Python 3.11** (перевірено на Windows із вбудованим `python-portable`).
- **PyTorch 2.x** з підтримкою CUDA (якщо використовуєте GPU).
- Додаткові бібліотеки: `gradio`, `ukrainian-word-stress`, `ipa-uk`, `transformers`, `styletts2_inference`, `huggingface_hub` та інші із `requirements.txt`.

### Особливості реалізації
- Вербалізатор працює офлайн та автоматично підбирає токенайзер (спершу `AutoTokenizer`, потім fallback на `MBart50TokenizerFast`).
- Для кожного голосу використовується `.pt` файл зі стилем; при відсутності вибраного голосу в multi-режимі береться перший доступний.
- Аудіофрагменти об'єднуються через `torch.cat`, а після синтезу повертається сигнал з частотою 24 кГц.
- Усі обчислення виконуються в режимі `torch.inference_mode()`.

---

## SoniTranslate UA

### Огляд
Портативна версія SoniTranslate автоматизує повний цикл дубляжу: завантаження відео або YouTube-аудіо, транскрипція WhisperX, синтез українського мовлення через StyleTTS2 та зворотне збирання аудіо/відео з субтитрами. Компоненти згруповано у пакет `sonitranslate_ua/`.

### Структура каталогу
```
sonitranslate_ua/
├── config/settings.py      # Глобальна конфігурація та створення директорій
├── install.py              # Встановлення залежностей з requirements.txt
├── main.py                 # Вхідна точка для запуску Gradio UI
├── pipeline/
│   ├── audio_processor.py  # Завантаження, конвертація та розбиття аудіо
│   ├── transcriber.py      # WhisperX транскрипція й діаризація
│   ├── tts_engine.py       # Український StyleTTS2 з пакетною обробкою
│   └── video_mixer.py      # Заміну аудіо доріжки й генерацію субтитрів
├── ui/gradio_interface.py  # Веб-інтерфейс з налаштуваннями та чергою задач
├── models/styletts2_ua/    # Очікуване розташування конфігів і чекпоінтів моделі
├── temp/                   # Проміжні файли (сегменти, субтитри, тимчасове аудіо)
└── examples/               # Приклади для тестування конвеєра
```

### Попередні вимоги
- **Python 3.10+** з установленим `pip` та відповідною версією PyTorch (CUDA за бажанням).
- Упаковані ресурси StyleTTS2 українською: помістіть `config.yml` та `epochs_2nd_00020.pth` у `sonitranslate_ua/models/styletts2_ua/`.
- Встановлений `ffmpeg` у системному `PATH` для коректного витягу аудіо та реміксу відео.

### Встановлення залежностей
```bash
python -m venv .venv
source .venv/bin/activate  # або .venv\Scripts\activate у Windows
python sonitranslate_ua/install.py
```
За потреби можна напряму виконати `pip install -r sonitranslate_ua/requirements.txt`.

### Запуск інтерфейсу
```bash
python sonitranslate_ua/run.py
```
Скрипт:
1. Створює необхідні каталоги (`models/`, `temp/`, `examples/`).
2. Відкриває Gradio Blocks-інтерфейс з вкладкою налаштувань (вибір джерела відео, режим голосу, параметри TTS) та панеллю результатів.
3. Автоматично ставить завдання у чергу, щоб паралельні запити оброблялися послідовно.

### Основні можливості інтерфейсу
- Завантаження локальних відео або посилань на YouTube із витягом аудіо.
- Увімкнення діаризації через WhisperX (за бажанням з Hugging Face token).
- Клонування голосу на основі зразка або використання стандартного українського голосу.
- Контроль дифузійних кроків та масштабу ембеддингу для стилізації синтезу.
- Експорт окремих доріжок (новий аудіофайл, відео з озвучкою, SRT-субтитри) та проміжних сегментів.

### Кешування та тимчасові файли
- Папка `temp/` використовується для сегментів WhisperX, проміжних TTS-файлів і тимчасових AAC доріжок.
- Очистити кеш можна вручну, видаливши вміст `sonitranslate_ua/temp/` після завершення роботи.

---

## Додаткові нотатки
- Обидва проєкти можуть співіснувати: експериментальний застосунок підходить для ручного синтезу, тоді як SoniTranslate UA автоматизує повний дубляж.
- Якщо плануєте розгортання на іншій машині, скопіюйте весь каталог `sonitranslate_ua/` разом із попередньо завантаженими моделями та використовуйте `run.py` для запуску.
